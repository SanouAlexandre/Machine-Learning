{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oXyF9ZjjdO4"
      },
      "source": [
        "# Linear regression\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "gO_05uo4jdO-",
        "outputId": "cd2eb3f5-33e9-40db-9289-a7c149e66434"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a sample of 180 values\n",
        "m = 180\n",
        "X = np.linspace(0, 10, m).reshape(m,1)\n",
        "y = X + np.random.randn(m, 1)\n",
        "\n",
        "plt.xlabel(\"Data linearly correlated\")\n",
        "plt.scatter(X, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "YyTju4CpjdPZ",
        "outputId": "3629ef91-9782-4ff5-dd2b-754449be5994"
      },
      "outputs": [],
      "source": [
        "# Create our linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "print(\"model score :\", model.score(X, y))\n",
        "\n",
        "plt.xlabel(\"regression line \")\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, model.predict(X), c='red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wVl6p90jdQS"
      },
      "source": [
        "# Polynomial regression\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "n_gLRv_ojdQW",
        "outputId": "ec67ecb2-b00c-46b3-e5e4-e010b7986fe0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
        "y = [99,95,70,55,55,50,60,75,80,70,85,76,78,75,93,98,98,103]\n",
        "model = np.poly1d(np.polyfit(x, y, 3))\n",
        "\n",
        "# We display the line, starting from point 1 to point 22 \n",
        "line = np.linspace(1, 22, 100)\n",
        "plt.scatter(x, y)\n",
        "plt.plot(line, model(line))\n",
        "plt.show()\n",
        "\n",
        "# Le score du modèle\n",
        "print(\" \")\n",
        "print(\"model score is :\", r2_score(y, model(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwTglmoSjdQb"
      },
      "source": [
        "# Le clustering K-moyennes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo7le510jdQg"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import datasets\n",
        "# This library helps to process data\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUC2nH2UjdQs",
        "outputId": "39b6bad8-4260-4232-9778-a9e1b10f03a7"
      },
      "outputs": [],
      "source": [
        "# Import Iris dataset \n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# create a dataframe\n",
        "df = pd.DataFrame(iris['data'])\n",
        "\n",
        "X = scale(iris.data)\n",
        "\n",
        "# Store flowers type\n",
        "y = pd.DataFrame(iris.target)\n",
        "variable_names = iris.feature_names\n",
        "print(\"first 10 values : \\n\", X[0:10,])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX6S0NQAjdRV"
      },
      "outputs": [],
      "source": [
        "# Optimum number of clusters using Kmeans method\n",
        "inertia_intraclass = []\n",
        "K = range(1,10)\n",
        "for k in K:\n",
        "    kmeanModel = KMeans(n_clusters=k)\n",
        "    kmeanModel.fit(df)\n",
        "    inertia_intraclass.append(kmeanModel.inertia_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "7RqhKMbIjdRb",
        "outputId": "ba528cfb-c72c-47d5-d131-70a5b7d9e07e"
      },
      "outputs": [],
      "source": [
        "# On affiche un graphique qui montre l'évolution de l’inertie intraclasses avec l'augmentation du nombre de clusters plt.figure(figsize=(8, 8))\n",
        "plt.plot(K, inertia_intraclass, 'bx-')\n",
        "plt.xlabel('Number of clusters K')\n",
        "plt.ylabel('Inertia intraclass')\n",
        "plt.title('Kmeans method shows the optimal numbers of clusters K \\n')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "gwO8ILQ6jdRf",
        "outputId": "10a4985e-a3fe-4600-d2f0-4acfc54c7400"
      },
      "outputs": [],
      "source": [
        "# On créer un objet Kmeans en l’instanciant avec 3 clusters\n",
        "k_average = KMeans(n_clusters=3)\n",
        "# Train the model\n",
        "k_average.fit(df)\n",
        "\n",
        "# Aply the prediction\n",
        "df['k_means'] = k_average.predict(df)\n",
        "df['target'] = iris['target']\n",
        "\n",
        "# Visualize clusters by color, green, yellow, red\n",
        "color_theme = np.array(['green', 'yellow', 'red'])\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(df[0], df[1], c=color_theme[k_average.labels_], s=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "per4uyNnjdRk"
      },
      "source": [
        "# Principal components Analysis clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzdvLyVAjdRo"
      },
      "outputs": [],
      "source": [
        "from sklearn import decomposition\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZPMOaGGjdRs",
        "outputId": "ba77e077-03fc-4628-c311-50860f9a7a88"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "variable_names = iris.feature_names\n",
        "print(\" First 10 lines :\\n\", X[0:10,])\n",
        "\n",
        "pca = decomposition.PCA()\n",
        "\n",
        "# Train the algorithm\n",
        "iris_pca = pca.fit_transform(X)\n",
        "\n",
        "# Percentage of variance explained by each four principal components\n",
        "print(\"Percentage of variance explained by each four principal components :\\n\",\n",
        "pca.explained_variance_ratio_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXU9LV-BjdRu"
      },
      "source": [
        "# Model choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "wiwSpVg-jdRw",
        "outputId": "ad83bc94-88bc-4992-b588-5bf02517952d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a sample of 200 values m = 200\n",
        "X = np.array([740, 880, 650, 1900, 1430])\n",
        "y = np.array([25, 35, 19, 103, 67])\n",
        "\n",
        "# Build the regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X.reshape(-1, 1), y)\n",
        "\n",
        "print(\"score is :\", model.score(X.reshape(-1, 1), y))\n",
        "print(\"With 1000 € you can pretend to an appartment of \", model.predict(np.array(1000).reshape(-1, 1)), \"m2\")\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X.reshape(-1, 1), model.predict(X.reshape(-1, 1)), c='red')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "c13_le_machine_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
