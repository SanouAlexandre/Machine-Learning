{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright (c) 2017 Anthony De Meulemeester "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "from ml_helpers import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('giskard_dataset.csv', delimiter=';')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets create a new frame with the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df = pd.DataFrame(parse_into_emails(df.Message))\n",
    "email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop emails with empty body, to or from_ columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.drop(email_df.query(\"body == '' | to == '' | from_ == ''\").index, inplace=True)\n",
    "email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we are going to tokenize the bodies and convert them into a document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ENGLISH_STOP_WORDS.union(['ect', 'hou', 'com', 'recipient'])\n",
    "vect = TfidfVectorizer(analyzer='word', stop_words=stopwords, max_df=0.4, min_df=0.2)\n",
    "\n",
    "X = vect.fit_transform(email_df.body)\n",
    "features = vect.get_feature_names()\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's print the top 10 terms in document 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_feats_in_doc(X, features, 1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we print the top terms across all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_mean_feats(X, features, None, 0.1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As clustering algorithm KMeams is a perfect fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "clf = KMeans(n_clusters=n_clusters, \n",
    "            max_iter=100, \n",
    "            init='k-means++', \n",
    "            n_init=1)\n",
    "labels = clf.fit_predict(X)\n",
    "\n",
    "#For larger datasets use mini-batch KMeans, so we dont have to read all data into memory.\n",
    "# batch_size = 500\n",
    "# clf = MiniBatchKMeans(n_clusters=n_clusters, init_size=1000, batch_size=batch_size, max_iter=100)  \n",
    "# clf.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot this with matplotlib to visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to make 2D coordinates from the sparse matrix.\n",
    "X_dense = X.todense()\n",
    "pca = PCA(n_components=2).fit(X_dense)\n",
    "coords = pca.transform(X_dense)\n",
    "\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets plot it again, but this time we add some color to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_colors = [\"#2AB0E9\", \"#2BAF74\", \"#D7665E\", \"#CCCCCC\", \n",
    "                \"#D2CA0D\", \"#522A64\", \"#A3DB05\", \"#FC6514\"]\n",
    "colors = [label_colors[i] for i in labels]\n",
    "\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = clf.cluster_centers_\n",
    "centroid_coords = pca.transform(centroids)\n",
    "plt.scatter(centroid_coords[:, 0], centroid_coords[:, 1], marker='X', s=200, linewidths=2, c='#444d60')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this to print the top terms per cluster with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tfidf_classfeats_h(top_feats_per_cluster(X, labels, features, 0.1, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pandas as pd\n",
    "\n",
    "from ml_helpers import parse_into_emails\n",
    "from ml_query import EmailDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just like in part_1, read and preprocess emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('giskard_dataset.csv', delimiter=';') \n",
    "email_df = pd.DataFrame(parse_into_emails(emails.Message))\n",
    "email_df.drop(email_df.query(\"body == '' | to == '' | from_ == ''\").index, inplace=True)\n",
    "\n",
    "stopwords = ENGLISH_STOP_WORDS.union(['ect', 'hou', 'com', 'recipient'])\n",
    "vec = TfidfVectorizer(analyzer='word', stop_words=stopwords, max_df=0.3, min_df=2)\n",
    "vec_train = vec.fit_transform(email_df.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print out the vector of the first email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(vec_train[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find cosine similarity between the first email and all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(vec_train[0:1], vec_train).flatten()\n",
    "\n",
    "# print out the cosine similarities\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding emails related to a query.\n",
    "query = \"john\"\n",
    "\n",
    "# Transform the query into the original vector\n",
    "vec_query = vec.transform([query])\n",
    "\n",
    "cosine_sim = linear_kernel(vec_query, vec_train).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 10 most related emails to the query.\n",
    "related_email_indices = cosine_sim.argsort()[:-10:-1]\n",
    "# print out the indices of the 10 most related emails.\n",
    "print(related_email_indices)\n",
    "\n",
    "# print out the first email \n",
    "first_email_index = related_email_indices[0]\n",
    "print(email_df.body[first_email_index])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dbeee07aa18e2c410ae6d31d6c19e586a0d6224d0a70b8bcacbf6868e7dcedd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
